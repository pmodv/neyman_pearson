# neyman_pearson
investigations of power and domination of rejection regions.

The Neyman-Pearson test statistic plays a crucial role in many evaluations and metrics of distribution divergence, including KL and Jensen-Shannon.

Furthermore, the concept of mutual information possesses a fundamental dependence to the Neyman-Pearson test statistic, and it is for this purpose, for better understanding mutual information and information gain/loss in deep learning and machine learning, in general.

I write my own helper functions, sticking to strictly FP practices.

